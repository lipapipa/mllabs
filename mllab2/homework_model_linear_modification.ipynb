{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc5a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import make_regression_data, mse, log_epoch, RegressionDataset\n",
    "\n",
    "class LinearRegressionManual:\n",
    "    def __init__(self, in_features):\n",
    "        self.w = torch.randn(in_features, 1, dtype=torch.float32, requires_grad=False)\n",
    "        self.b = torch.zeros(1, dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return X @ self.w + self.b\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.dw = torch.zeros_like(self.w)\n",
    "        self.db = torch.zeros_like(self.b)\n",
    "    \n",
    "\n",
    "    def l1_regularization(self):\n",
    "        \"\"\"L1-регуляризация (Lasso): возвращает сумму |w|\"\"\"\n",
    "        return torch.sum(torch.abs(self.w))\n",
    "\n",
    "    def l2_regularization(self):\n",
    "        \"\"\"L2-регуляризация (Ridge): возвращает сумму w^2\"\"\"\n",
    "        return torch.sum(self.w ** 2)\n",
    "\n",
    "    def backward(self, X, y, y_pred):\n",
    "        n = X.shape[0]\n",
    "        error = y_pred - y\n",
    "        self.dw = (X.T @ error) / n\n",
    "        self.db = error.mean(0)\n",
    "\n",
    "        if self.l1_lambda > 0:\n",
    "            self.dw += self.l1_lambda * torch.sign(self.w)  # Производная |w| = sign(w)\n",
    "        if self.l2_lambda > 0:\n",
    "            self.dw += 2 * self.l2_lambda * self.w         # Производная w^2 = 2w\n",
    "        \n",
    "        \n",
    "\n",
    "    def step(self, lr):\n",
    "        self.w -= lr * self.dw\n",
    "        self.b -= lr * self.db\n",
    "\n",
    "    def set_l1_lambda(self, lambda_):\n",
    "        \"\"\"Установка коэффициента L1-регуляризации\"\"\"\n",
    "        self.l1_lambda = lambda_\n",
    "\n",
    "    def set_l2_lambda(self, lambda_):\n",
    "        \"\"\"Установка коэффициента L2-регуляризации\"\"\"\n",
    "        self.l2_lambda = lambda_\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save({'w': self.w, 'b': self.b}, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        state = torch.load(path)\n",
    "        self.w = state['w']\n",
    "        self.b = state['b']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312bb6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: 200\n",
      "Количество батчей: 7\n",
      "Пример данных: (tensor([0.4992]), tensor([-0.0954]))\n",
      "Epoch 10: loss=0.2361\n",
      "Epoch 20: loss=0.1245\n",
      "Epoch 30: loss=0.0738\n",
      "Epoch 40: loss=0.0540\n",
      "Epoch 50: loss=0.0445\n",
      "Epoch 60: loss=0.0392\n",
      "Epoch 70: loss=0.0369\n",
      "Epoch 80: loss=0.0363\n",
      "83 tensor(0.0361)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Генерируем данные\n",
    "    X, y = make_regression_data(n=200)\n",
    "    \n",
    "    # Создаём датасет и даталоадер\n",
    "    dataset = RegressionDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    print(f'Размер датасета: {len(dataset)}')\n",
    "    print(f'Количество батчей: {len(dataloader)}')\n",
    "    print(f'Пример данных: {dataset[0]}')\n",
    "    \n",
    "    # Обучаем модель\n",
    "    model = LinearRegressionManual(in_features=1)\n",
    "    model.set_l1_lambda(0.01)  # Включить L1 с lambda=0.01\n",
    "    model.set_l2_lambda(0.001) # Включить L2 с lambda=0.001\n",
    "    lr = 0.1\n",
    "    epochs = 100\n",
    "    best_loss = float(\"inf\")\n",
    "    waiting_Epoch = 10\n",
    "    no_improve = 0\n",
    "\n",
    "    \n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
    "            y_pred = model(batch_X)\n",
    "            loss = mse(y_pred, batch_y)\n",
    "            total_loss += loss + model.l1_lambda * model.l1_regularization()\n",
    "            total_loss += model.l2_lambda * model.l2_regularization()\n",
    "            \n",
    "            model.zero_grad()\n",
    "            model.backward(batch_X, batch_y, y_pred)\n",
    "            model.step(lr)\n",
    "            \n",
    "        \n",
    "        avg_loss = total_loss / (i + 1)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            log_epoch(epoch, avg_loss)\n",
    "        \n",
    "        if (best_loss-avg_loss)>0.001:\n",
    "            best_loss = avg_loss\n",
    "            no_improve = 0\n",
    "\n",
    "        else:\n",
    "            no_improve+=1\n",
    "            if waiting_Epoch< no_improve:\n",
    "\n",
    "                print(epoch,best_loss)\n",
    "                break\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    model.save('linreg_manual.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
