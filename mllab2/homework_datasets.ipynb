{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fa6a8f",
   "metadata": {},
   "source": [
    "я сделал второе задание только для линейной регрессии, так как не особо умею работаать с классификацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05de6755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, filepath, target_col='Price', test_size=0.2, random_state=42):\n",
    "        # Загрузка данных\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Определение типов колонок\n",
    "        self.num_col = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "        self.cat_col = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        self.target_col = target_col\n",
    "        \n",
    "        # Удаление целевой из списков признаков\n",
    "        if self.target_col in self.num_col:\n",
    "            self.num_col.remove(self.target_col)\n",
    "        if self.target_col in self.cat_col:\n",
    "            self.cat_col.remove(self.target_col)\n",
    "        \n",
    "        # Предобработка\n",
    "        df[self.num_col] = df[self.num_col].fillna(0)\n",
    "        df[self.cat_col] = df[self.cat_col].fillna('other')\n",
    "        df = df.drop_duplicates()\n",
    "        \n",
    "        # One-Hot Encoding\n",
    "        self.ohe = OneHotEncoder(sparse_output=False)\n",
    "        encoded_cat = self.ohe.fit_transform(df[self.cat_col])\n",
    "        encoded_df = pd.DataFrame(encoded_cat, columns=self.ohe.get_feature_names_out(self.cat_col))\n",
    "        \n",
    "        # Создание финального датасета\n",
    "        final_df = pd.concat([df[self.num_col], encoded_df, df[[self.target_col]]], axis=1)\n",
    "        \n",
    "        # Удаление константных колонок\n",
    "        constant_cols = [col for col in final_df.columns if final_df[col].nunique() == 1]\n",
    "        self.final_df = final_df.drop(columns=constant_cols)\n",
    "        \n",
    "        # Разделение данных\n",
    "        X = self.final_df.drop(self.target_col, axis=1).values\n",
    "        y = self.final_df[self.target_col].values\n",
    "        \n",
    "        # Масштабирование\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.power_trans = PowerTransformer()\n",
    "        y_scaled = self.power_trans.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Разделение на train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y_scaled, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Преобразование в тензоры\n",
    "        self.X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        self.y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "        self.X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "        self.y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "        \n",
    "    def get_train_data(self):\n",
    "        return self.X_train, self.y_train\n",
    "    \n",
    "    def get_test_data(self):\n",
    "        return self.X_test, self.y_test\n",
    "    \n",
    "    def inverse_transform_target(self, y):\n",
    "        return self.power_trans.inverse_transform(y.numpy().reshape(-1, 1))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.y_train[idx]\n",
    "\n",
    "class LinearRegressionManual:\n",
    "    def __init__(self, in_features):\n",
    "        self.w = torch.randn(in_features, 1, dtype=torch.float32, requires_grad=False)\n",
    "        self.b = torch.zeros(1, dtype=torch.float32, requires_grad=False)\n",
    "        self.l1_lambda = 0\n",
    "        self.l2_lambda = 0\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return X @ self.w + self.b\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.dw = torch.zeros_like(self.w)\n",
    "        self.db = torch.zeros_like(self.b)\n",
    "    \n",
    "    def l1_regularization(self):\n",
    "        return torch.sum(torch.abs(self.w))\n",
    "\n",
    "    def l2_regularization(self):\n",
    "        return torch.sum(self.w ** 2)\n",
    "\n",
    "    def backward(self, X, y, y_pred):\n",
    "        n = X.shape[0]\n",
    "        error = y_pred - y\n",
    "        self.dw = (X.T @ error) / n\n",
    "        self.db = error.mean(0)\n",
    "\n",
    "        if self.l1_lambda > 0:\n",
    "            self.dw += self.l1_lambda * torch.sign(self.w)\n",
    "        if self.l2_lambda > 0:\n",
    "            self.dw += 2 * self.l2_lambda * self.w\n",
    "    \n",
    "    def step(self, lr):\n",
    "        self.w -= lr * self.dw\n",
    "        self.b -= lr * self.db\n",
    "\n",
    "    def set_l1_lambda(self, lambda_):\n",
    "        self.l1_lambda = lambda_\n",
    "\n",
    "    def set_l2_lambda(self, lambda_):\n",
    "        self.l2_lambda = lambda_\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save({'w': self.w, 'b': self.b}, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        state = torch.load(path)\n",
    "        self.w = state['w']\n",
    "        self.b = state['b']\n",
    "\n",
    "def mse(y_pred, y_true):\n",
    "    return torch.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
    "    return 1 - ss_res / ss_tot\n",
    "\n",
    "def log_epoch(epoch, loss, r2):\n",
    "    print(f'Epoch {epoch:3d} | Loss: {loss:.4f} | R²: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd50656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 | Loss: 0.0658 | R²: 0.9294\n",
      "\n",
      "Ранняя остановка на эпохе 18\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Инициализация и загрузка данных\n",
    "    dataset = CustomDataset('sales_data.csv')\n",
    "    X_train, y_train = dataset.get_train_data()\n",
    "    X_test, y_test = dataset.get_test_data()\n",
    "    \n",
    "    # Создание DataLoader\n",
    "    train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(list(zip(X_test, y_test)), batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Инициализация модели\n",
    "    in_features = X_train.shape[1]\n",
    "    model = LinearRegressionManual(in_features)\n",
    "    #установка параметров l1 l2\n",
    "    model.set_l1_lambda(0.01)\n",
    "    model.set_l2_lambda(0.001)\n",
    "    \n",
    "    # Обучение\n",
    "    lr = 0.01\n",
    "    epochs = 100\n",
    "    best_loss = float('inf')\n",
    "    patience = 10\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, (batch_X, batch_y) in enumerate(train_loader):\n",
    "            y_pred = model(batch_X)\n",
    "            loss = mse(y_pred, batch_y)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            if model.l1_lambda > 0:\n",
    "                total_loss += model.l1_lambda * model.l1_regularization().item()\n",
    "            if model.l2_lambda > 0:\n",
    "                total_loss += model.l2_lambda * model.l2_regularization().item()\n",
    "            \n",
    "            model.zero_grad()\n",
    "            model.backward(batch_X, batch_y, y_pred)\n",
    "            model.step(lr)\n",
    "        \n",
    "        # Оценка на тестовом наборе\n",
    "        test_preds = []\n",
    "        test_true = []\n",
    "        \n",
    "        for batch_X, batch_y in test_loader:\n",
    "            y_pred = model(batch_X)\n",
    "            test_preds.append(y_pred)\n",
    "            test_true.append(batch_y)\n",
    "        \n",
    "        test_preds = torch.cat(test_preds)\n",
    "        test_true = torch.cat(test_true)\n",
    "        test_loss = mse(test_preds, test_true).item()\n",
    "        r2_sc = r2_score(test_preds,test_true)\n",
    "        \n",
    "        avg_loss = total_loss / (i + 1)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            log_epoch(epoch, test_loss, r2_sc)\n",
    "        \n",
    "        # Ранняя остановка\n",
    "        if (best_loss - avg_loss) > 0.001:\n",
    "            best_loss = avg_loss\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"\\nРанняя остановка на эпохе {epoch}\")\n",
    "                break\n",
    "    \n",
    "    # Сохранение модели\n",
    "    model.save('linreg_manual_price.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
